# Pipeline de Datos de Criptomonedas

Un pipeline completo para la obtenci√≥n, almacenamiento y an√°lisis de datos de precios de criptomonedas.

## Descripci√≥n General del Proyecto

Este proyecto proporciona un flujo de trabajo completo para:
1. Obtener datos hist√≥ricos de criptomonedas desde la API de CoinGecko
2. Almacenar datos en una base de datos PostgreSQL
3. Analizar tendencias y patrones de precios
4. Construir y evaluar modelos predictivos

## Estructura del Proyecto

```
crypto-data-pipeline/
‚îú‚îÄ‚îÄ crypto_app/                  # M√≥dulos CLI y conexi√≥n a API/DB
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                   # Punto de entrada con comandos: get-history, bulk-process, --store-db
‚îÇ   ‚îú‚îÄ‚îÄ coingecko_client.py      # L√≥gica HTTP / an√°lisis de JSON
‚îÇ   ‚îî‚îÄ‚îÄ db.py                    # Conexi√≥n SQLAlchemy, inserciones y upserts mensuales
‚îÇ   ‚îî‚îÄ‚îÄ daily_fetch.py           # Script para ejecuci√≥n diaria programada
‚îÇ
‚îú‚îÄ‚îÄ sql/                         # Consultas SQL
‚îÇ   ‚îú‚îÄ‚îÄ create_tables.sql        # Creaci√≥n de tablas DDL
‚îÇ   ‚îî‚îÄ‚îÄ analysis_queries.sql     # Consultas DQL para promedios mensuales y an√°lisis de recuperaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ analysis/                    # Scripts de an√°lisis en Python
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py   # Generaci√≥n de caracter√≠sticas + exportaci√≥n de CSV/gr√°ficos
‚îÇ   ‚îî‚îÄ‚îÄ regression.py            # Entrenamiento/evaluaci√≥n de modelos
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # Notebooks Jupyter para exploraci√≥n interactiva
‚îÇ   ‚îî‚îÄ‚îÄ coin_analysis.ipynb
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Directorio de salida (JSONs, im√°genes, CSVs)
‚îÇ
‚îú‚îÄ‚îÄ logs/                        # Archivos de registro de la aplicaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                   # Imagen Python de la aplicaci√≥n
‚îú‚îÄ‚îÄ docker-compose.yml           # Orquesta la app + PostgreSQL con montaje de datos
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias del proyecto
‚îú‚îÄ‚îÄ .gitignore                   # Reglas de ignorar en Git
‚îî‚îÄ‚îÄ README.md                    # Documentaci√≥n del proyecto
```

## Instalaci√≥n

### Opci√≥n 1: Usando Docker (Recomendado)

1. Aseg√∫rate de tener Docker y Docker Compose instalados en tu sistema.

2. Clona el repositorio:
   ```
   git clone https://github.com/facundofernandezmiguez/crypto-data-pipeline.git
   cd crypto-data-pipeline
   ```

3. Inicia los servicios:
   ```
   docker-compose up -d
   ```

Esto iniciar√° tanto la aplicaci√≥n Python como la base de datos PostgreSQL.

### Opci√≥n 2: Instalaci√≥n Manual

1. Clona el repositorio:
   ```
   git clone https://github.com/facundofernandezmiguez/crypto-data-pipeline.git
   cd crypto-data-pipeline
   ```

2. Crea y activa un entorno virtual:
   ```
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. Instala las dependencias:
   ```
   pip install -r requirements.txt
   ```

4. Configura PostgreSQL por separado e inicializa la base de datos:
   ```
   psql -U postgres -f sql/create_tables.sql
   ```

## Uso

### Interfaz de L√≠nea de Comandos

La CLI proporciona varios comandos para la obtenci√≥n y procesamiento de datos:

#### 1. Getting crypto token data üí∏

```
python -m crypto_app.cli get-history --coin bitcoin --date 2025-01-01
```

Si tambi√©n quieres almacenar los datos en la base de datos:

```
python -m crypto_app.cli get-history --coin bitcoin --date 2025-01-01 --store-db
```

#### 2. Procesamiento diario automatizado

Para ejecutar la obtenci√≥n diaria de datos para bitcoin, ethereum y cardano:

```
python -m crypto_app.daily_fetch
```

Para ver las instrucciones de configuraci√≥n de tareas programadas:

```
python -m crypto_app.daily_fetch --setup
```

#### 3. Procesamiento en lote para un rango de fechas

Para procesar un rango de fechas de forma secuencial:

```
python -m crypto_app.cli bulk-process --coin bitcoin --start-date 2023-01-01 --end-date 2023-01-31
```

Para procesamiento concurrente (m√°s r√°pido):

```
python -m crypto_app.cli bulk-process --coin bitcoin --start-date 2023-01-01 --end-date 2023-01-31 --concurrent
```

Para almacenar tambi√©n en la base de datos:

```
python -m crypto_app.cli bulk-process --coin bitcoin --start-date 2023-01-01 --end-date 2023-01-31 --store-db
```


## Ejemplos de Ejecuci√≥n con Docker

Para ejecutar comandos espec√≠ficos usando Docker:

```
docker-compose run app get-history --coin bitcoin --date 2025-01-01 --store-db
```

Para el procesamiento en lote con Docker:

```
docker-compose run app bulk-process --coin bitcoin --start-date 2025-01-01 --end-date 2025-05-13 --store-db

docker-compose run app bulk-process --coin ethereum --start-date 2025-01-01 --end-date 2025-05-13 --store-db

docker-compose run app bulk-process --coin cardano --start-date 2025-01-01 --end-date 2025-05-13 --store-db
```
Aclaraci√≥n: debido a que esta es la versi√≥n free de la api, muchas veces se alcanza el rate limit. Tuve que reejecutar varias veces algunas fechas especificas para obtener todos los datos.

## Variables de Entorno

Crea un archivo `.env` con las siguientes variables:

```
DATABASE_URL=postgresql://username:password@localhost:5432/crypto
COINGECKO_API_KEY=tu_api_key_si_est√°_disponible
```

## 2. Loading data into the database

### üõ†Ô∏è Creaci√≥n de tablas en PostgreSQL

Para inicializar la base de datos con las tablas necesarias (coin_history y coin_monthly_aggregates), sigue estos pasos:

1. **Aseg√∫rate de estar en el directorio del proyecto**
   ```bash
   cd crypto-data-pipeline
   ```

2. **Verificar que el archivo SQL existe**
   ```bash
   dir sql\create_tables.sql
   ```

3. **Copiar el archivo al contenedor de PostgreSQL**
   ```bash
   docker cp sql/create_tables.sql crypto-data-pipeline-db-1:/create_tables.sql
   ```
   Aseg√∫rate de reemplazar el nombre del contenedor si usas uno distinto.

4. **Ejecutar el script SQL en la base de datos**
   ```bash
   docker exec -it crypto-data-pipeline-db-1 psql -U postgres -d postgres -f /create_tables.sql
   ```
   Deber√≠as ver mensajes como CREATE TABLE, CREATE INDEX, y COMMENT, indicando que las tablas fueron creadas exitosamente.

5. **Verificar que las tablas fueron creadas**
   ```bash
   docker exec -it crypto-data-pipeline-db-1 psql -U postgres -d postgres
   ```
   Y dentro del shell de PostgreSQL, ejecuta:
   ```sql
   \dt
   ```
   Deber√≠as ver:
   ```
              List of relations
  Schema |          Name           | Type  |  Owner
 --------+-------------------------+-------+----------
  public | coin_history            | table | postgres
  public | coin_monthly_aggregates | table | postgres
   ```

### E3. Analysing coin data with SQL üëì

Para responder a las preguntas de la Secci√≥n 3, sigue estos pasos:

1. **Cargar datos desde archivos JSON a la base de datos**

   Primero, carga los datos JSON a la base de datos ejecutando el script `load_data.py`:

   ```bash
   python load_data.py
   ```

   Este script busca todos los archivos JSON en la carpeta `data/` y los carga en la tabla `coin_history`.

2. **Con√©ctate a la base de datos PostgreSQL**
   ```bash
   docker-compose exec db psql -U postgres -d postgres
   ```

3. **Ejecutar las consultas SQL desde el archivo `analysis_queries.sql`**
   
   El archivo `analysis_queries.sql` contiene dos consultas principales para responder a las preguntas de la Secci√≥n 3:
   
   - **Query 1**: Calcula el precio promedio por mes para cada moneda
   - **Query 2**: Calcula el aumento despu√©s de ca√≠das consecutivas de m√°s de 3 d√≠as

   Puedes copiar y pegar estas consultas desde el archivo, o ejecutar el archivo completo con:

   ```sql
   \i /sql/analysis_queries.sql
   ```

4. **Para guardar los resultados en archivos**
   ```sql
   \o resultados_precio_mensual.txt
   -- Aqu√≠ va la consulta 1 (precio promedio por mes)
   \o
   
   \o resultados_aumento_tras_caidas.txt
   -- Aqu√≠ va la consulta 2 (aumento tras ca√≠das consecutivas)
   \o
   ```

Consulta el archivo `sql/analysis_queries.sql` para ver la documentaci√≥n detallada de las consultas.

## Ejecuci√≥n Programada

La aplicaci√≥n incluye funcionalidad para ejecutarse autom√°ticamente cada d√≠a a las 3:00 AM y obtener datos para bitcoin, ethereum y cardano.

### Configuraci√≥n en Windows

Ejecuta el siguiente comando para ver las instrucciones de configuraci√≥n:

```
python -m crypto_app.daily_fetch --setup
```

Sigue las instrucciones proporcionadas para configurar el Programador de tareas de Windows.

### Configuraci√≥n en Linux

En sistemas Linux, puedes configurar un trabajo cron ejecutando:

```
python -m crypto_app.daily_fetch --setup
```

Sigue las instrucciones para agregar la entrada necesaria a tu crontab.

## 4. Finance Meets Data Science

Navegar al directorio del proyecto e iniciar los contenedores

```
cd c:/Users/corebi/MLE Mutt/crypto-data-pipeline
docker-compose up -d
```

Ejecutar las notebooks de an√°lisis exploratorio de datos y de predicci√≥n de precios